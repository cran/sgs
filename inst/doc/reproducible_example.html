<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Fabio Feser" />

<meta name="date" content="2023-08-21" />

<title>SGS reproducible example</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">SGS reproducible example</h1>
<h4 class="author">Fabio Feser</h4>
<h4 class="date">2023-08-21</h4>



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Sparse-group SLOPE (SGS) is a penalised regression approach that
performs bi-level selection with FDR control under orthogonal designs.
SGS is described in detail in .</p>
<p>The method is implemented in the <code>sgs</code> R package. The
package has implementations for Gaussian and Binomial responses, both of
which are demonstrated here.</p>
</div>
<div id="gaussian-response" class="section level1">
<h1>Gaussian response</h1>
<div id="data" class="section level3">
<h3>Data</h3>
<p>For this example, a <span class="math inline">\(400\times
500\)</span> input matrix is used with a simple grouping structure,
sampled from a multivariate Gaussian distribution with no
correlation.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(sgs)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>groups <span class="ot">=</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">each=</span><span class="dv">3</span>),</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">21</span><span class="sc">:</span><span class="dv">40</span>, <span class="at">each=</span><span class="dv">4</span>),</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">41</span><span class="sc">:</span><span class="dv">60</span>, <span class="at">each=</span><span class="dv">5</span>),</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">61</span><span class="sc">:</span><span class="dv">80</span>, <span class="at">each=</span><span class="dv">6</span>),</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">81</span><span class="sc">:</span><span class="dv">100</span>, <span class="at">each=</span><span class="dv">7</span>))</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">generate_toy_data</span>(<span class="at">p=</span><span class="dv">500</span>, <span class="at">n=</span><span class="dv">400</span>, <span class="at">groups =</span> groups, <span class="at">seed_id=</span><span class="dv">3</span>)</span></code></pre></div>
</div>
<div id="fitting-an-sgs-model" class="section level3">
<h3>Fitting an SGS model</h3>
<p>We now fit an SGS model to the data using linear regression. The SGS
model has many different hyperparameters which can be tuned/selected. Of
particular importance is the <span class="math inline">\(\lambda\)</span> parameter, which defines the
level of sparsity in the model. First, we select this manually and then
next use cross-validation to tune it. The other parameters we leave as
their default values, although they can easily be changed.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>model <span class="ot">=</span> <span class="fu">fit_sgs</span>(<span class="at">X =</span> data<span class="sc">$</span>X, <span class="at">y =</span> data<span class="sc">$</span>y, <span class="at">groups =</span> groups, <span class="at">type=</span><span class="st">&quot;linear&quot;</span>, <span class="at">lambda =</span> <span class="dv">1</span>, <span class="at">alpha=</span><span class="fl">0.95</span>, <span class="at">vFDR=</span><span class="fl">0.1</span>, <span class="at">gFDR=</span><span class="fl">0.1</span>, <span class="at">standardise =</span> <span class="st">&quot;l2&quot;</span>, <span class="at">intercept =</span> <span class="cn">TRUE</span>, <span class="at">verbose=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>Note: we have fit an intercept and applied <span class="math inline">\(\ell_2\)</span> standardisation. This is the
recommended usage when applying SGS.</p>
</div>
<div id="output-of-model" class="section level3">
<h3>Output of model</h3>
<p>The package provides several useful outputs after fitting a model.
The vector shows the fitted values (note the intercept). We can also
recover the indices of the non-zero variables and groups, which are
indexed from the first variable, not the intercept.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>model<span class="sc">$</span>beta[model<span class="sc">$</span>selected_var<span class="sc">+</span><span class="dv">1</span>,]</span></code></pre></div>
<pre><code>##       v100       v136       v234       v334 
##  1.2211478  3.0393493  2.4211141 -0.4108451</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>model<span class="sc">$</span>group.effects[model<span class="sc">$</span>selected_group,]</span></code></pre></div>
<pre><code>##       G30       G39       G59       G76 
## 1.2211478 3.0393493 2.4211141 0.4108451</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>model<span class="sc">$</span>selected_var</span></code></pre></div>
<pre><code>## [1] 100 136 234 334</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>model<span class="sc">$</span>selected_group</span></code></pre></div>
<pre><code>## [1] 30 39 59 76</code></pre>
<p>Defining a function that lets us calculate various metrics (including
the FDR and sensitivity):</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>fdr_sensitivity <span class="ot">=</span> <span class="cf">function</span>(fitted_ids, true_ids,num_coef){</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>  <span class="co"># calculates FDR, FPR, and sensitivity</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  num_true <span class="ot">=</span> <span class="fu">length</span>(<span class="fu">intersect</span>(fitted_ids,true_ids))</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  num_false <span class="ot">=</span> <span class="fu">length</span>(fitted_ids) <span class="sc">-</span> num_true</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  num_missed <span class="ot">=</span> <span class="fu">length</span>(true_ids) <span class="sc">-</span> num_true</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>  num_true_negatives <span class="ot">=</span> num_coef <span class="sc">-</span> <span class="fu">length</span>(true_ids)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>  out<span class="ot">=</span><span class="fu">c</span>()</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  out<span class="sc">$</span>fdr <span class="ot">=</span> num_false <span class="sc">/</span> (num_true <span class="sc">+</span> num_false)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.nan</span>(out<span class="sc">$</span>fdr)){out<span class="sc">$</span>fdr <span class="ot">=</span> <span class="dv">0</span>}</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>  out<span class="sc">$</span>sensitivity <span class="ot">=</span> num_true <span class="sc">/</span> <span class="fu">length</span>(true_ids)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">length</span>(true_ids) <span class="sc">==</span> <span class="dv">0</span>){</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    out<span class="sc">$</span>sensitivity <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>  }</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>  out<span class="sc">$</span>fpr <span class="ot">=</span> num_false <span class="sc">/</span> num_true_negatives</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>  out<span class="sc">$</span>f1 <span class="ot">=</span> (<span class="dv">2</span><span class="sc">*</span>num_true)<span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>num_true <span class="sc">+</span> num_false <span class="sc">+</span> num_missed)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.nan</span>(out<span class="sc">$</span>f1)){out<span class="sc">$</span>f1 <span class="ot">=</span> <span class="dv">1</span>}</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>  <span class="fu">return</span>(out)</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>}</span></code></pre></div>
<p>Calculating relevant metrics give</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">fdr_sensitivity</span>(<span class="at">fitted_ids =</span> model<span class="sc">$</span>selected_var, <span class="at">true_ids =</span> data<span class="sc">$</span>true_var_id, <span class="at">num_coef =</span> <span class="dv">500</span>)</span></code></pre></div>
<pre><code>## $fdr
## [1] 0
## 
## $sensitivity
## [1] 0.1428571
## 
## $fpr
## [1] 0
## 
## $f1
## [1] 0.25</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">fdr_sensitivity</span>(<span class="at">fitted_ids =</span> model<span class="sc">$</span>selected_group, <span class="at">true_ids =</span> data<span class="sc">$</span>true_grp_id, <span class="at">num_coef =</span> <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## $fdr
## [1] 0
## 
## $sensitivity
## [1] 0.4
## 
## $fpr
## [1] 0
## 
## $f1
## [1] 0.5714286</code></pre>
<p>The model is currently too sparse, as our choice of <span class="math inline">\(\lambda\)</span> is too high. We can instead use
cross-validation.</p>
</div>
<div id="cross-validation" class="section level3">
<h3>Cross validation</h3>
<p>Cross-validation is used to fit SGS models along a <span class="math inline">\(\lambda\)</span> path of length <span class="math inline">\(20\)</span>. The first value, <span class="math inline">\(\lambda_\text{max}\)</span>, is chosen to give the
null model and the path is terminated at <span class="math inline">\(\lambda_\text{min} = min_frac \dot
\lambda_\text{max}\)</span>. The 1se rule (as in the package) is used to
choose the optimal model.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>cv_model <span class="ot">=</span> <span class="fu">fit_sgs_cv</span>(<span class="at">X =</span> data<span class="sc">$</span>X, <span class="at">y =</span> data<span class="sc">$</span>y, <span class="at">groups=</span>groups, <span class="at">type =</span> <span class="st">&quot;linear&quot;</span>, <span class="at">nlambda =</span> <span class="dv">20</span>, <span class="at">nfolds=</span><span class="dv">10</span>, <span class="at">alpha =</span> <span class="fl">0.95</span>, <span class="at">vFDR =</span> <span class="fl">0.1</span>, <span class="at">gFDR =</span> <span class="fl">0.1</span>, <span class="at">min_frac =</span> <span class="fl">0.05</span>, <span class="at">standardise=</span><span class="st">&quot;l2&quot;</span>,<span class="at">intercept=</span><span class="cn">TRUE</span>,<span class="at">verbose=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Lambda 1/20 done. Lambda: 1.8388. Number of non-zero: 0. Error: 9522.47623165794. Avg iter: 7&quot;
## [1] &quot;Lambda 2/20 done. Lambda: 1.5706. Number of non-zero: 1. Error: 9121.87427456379. Avg iter: 26&quot;
## [1] &quot;Lambda 3/20 done. Lambda: 1.3415. Number of non-zero: 2. Error: 8348.10001181521. Avg iter: 31&quot;
## [1] &quot;Lambda 4/20 done. Lambda: 1.1458. Number of non-zero: 3. Error: 7525.33322733818. Avg iter: 35&quot;
## [1] &quot;Lambda 5/20 done. Lambda: 0.9787. Number of non-zero: 8. Error: 6706.42167334536. Avg iter: 35&quot;
## [1] &quot;Lambda 6/20 done. Lambda: 0.8359. Number of non-zero: 14. Error: 5509.29608346792. Avg iter: 44&quot;
## [1] &quot;Lambda 7/20 done. Lambda: 0.714. Number of non-zero: 15. Error: 4256.09986924448. Avg iter: 37&quot;
## [1] &quot;Lambda 8/20 done. Lambda: 0.6098. Number of non-zero: 15. Error: 3281.14251906525. Avg iter: 37&quot;
## [1] &quot;Lambda 9/20 done. Lambda: 0.5209. Number of non-zero: 15. Error: 2559.14833615298. Avg iter: 37&quot;
## [1] &quot;Lambda 10/20 done. Lambda: 0.4449. Number of non-zero: 19. Error: 2011.70593862728. Avg iter: 36&quot;
## [1] &quot;Lambda 11/20 done. Lambda: 0.38. Number of non-zero: 22. Error: 1552.91875758507. Avg iter: 39&quot;
## [1] &quot;Lambda 12/20 done. Lambda: 0.3246. Number of non-zero: 22. Error: 1179.20560203183. Avg iter: 33&quot;
## [1] &quot;Lambda 13/20 done. Lambda: 0.2772. Number of non-zero: 22. Error: 892.913519340801. Avg iter: 32&quot;
## [1] &quot;Lambda 14/20 done. Lambda: 0.2368. Number of non-zero: 22. Error: 682.816068341828. Avg iter: 34&quot;
## [1] &quot;Lambda 15/20 done. Lambda: 0.2022. Number of non-zero: 24. Error: 525.918317926705. Avg iter: 36&quot;
## [1] &quot;Lambda 16/20 done. Lambda: 0.1727. Number of non-zero: 24. Error: 405.623243053464. Avg iter: 37&quot;
## [1] &quot;Lambda 17/20 done. Lambda: 0.1475. Number of non-zero: 26. Error: 314.722794039507. Avg iter: 39&quot;
## [1] &quot;Lambda 18/20 done. Lambda: 0.126. Number of non-zero: 26. Error: 244.495442693249. Avg iter: 39&quot;
## [1] &quot;Lambda 19/20 done. Lambda: 0.1076. Number of non-zero: 27. Error: 192.736115731821. Avg iter: 40&quot;
## [1] &quot;Lambda 20/20 done. Lambda: 0.0919. Number of non-zero: 27. Error: 154.39418403602. Avg iter: 41&quot;</code></pre>
<p>The fitting verbose contains useful information, showing the error
for each <span class="math inline">\(\lambda\)</span> values, as well as
the number of non-zero parameters. Aside from the fitting verbose, we
can see a more succinct summary by using the function</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">print</span>(cv_model)</span></code></pre></div>
<pre><code>## 
##  regression type:  linear 
## 
##          lambda     error estimated_non_zero
##  [1,] 1.8387781 9522.4762                  0
##  [2,] 1.5705583 9121.8743                  1
##  [3,] 1.3414633 8348.1000                  2
##  [4,] 1.1457860 7525.3332                  3
##  [5,] 0.9786519 6706.4217                  8
##  [6,] 0.8358975 5509.2961                 14
##  [7,] 0.7139663 4256.0999                 15
##  [8,] 0.6098211 3281.1425                 15
##  [9,] 0.5208674 2559.1483                 15
## [10,] 0.4448893 2011.7059                 19
## [11,] 0.3799940 1552.9188                 22
## [12,] 0.3245648 1179.2056                 22
## [13,] 0.2772210  892.9135                 22
## [14,] 0.2367832  682.8161                 22
## [15,] 0.2022440  525.9183                 24
## [16,] 0.1727430  405.6232                 24
## [17,] 0.1475452  314.7228                 26
## [18,] 0.1260230  244.4954                 26
## [19,] 0.1076402  192.7361                 27
## [20,] 0.0919389  154.3942                 27</code></pre>
<p>The best model is found to be the one at the end of the path.
Checking the metrics again, we see how CV has generated a model with the
correct amount of sparsity that gives FDR levels below the specified
values.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="fu">fdr_sensitivity</span>(<span class="at">fitted_ids =</span> cv_model<span class="sc">$</span>fit<span class="sc">$</span>selected_var, <span class="at">true_ids =</span> data<span class="sc">$</span>true_var_id, <span class="at">num_coef =</span> <span class="dv">500</span>)</span></code></pre></div>
<pre><code>## $fdr
## [1] 0.03703704
## 
## $sensitivity
## [1] 0.9285714
## 
## $fpr
## [1] 0.002118644
## 
## $f1
## [1] 0.9454545</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="fu">fdr_sensitivity</span>(<span class="at">fitted_ids =</span> cv_model<span class="sc">$</span>fit<span class="sc">$</span>selected_group, <span class="at">true_ids =</span> data<span class="sc">$</span>true_grp_id, <span class="at">num_coef =</span> <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## $fdr
## [1] 0.09090909
## 
## $sensitivity
## [1] 1
## 
## $fpr
## [1] 0.01111111
## 
## $f1
## [1] 0.952381</code></pre>
</div>
<div id="plot" class="section level3">
<h3>Plot</h3>
<p>We can visualise the solution using the plot function</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">plot</span>(cv_model,<span class="at">how_many =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="prediction" class="section level3">
<h3>Prediction</h3>
<p>The package has an implemented predict function, to allow for easy
prediction</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">predict</span>(model,data<span class="sc">$</span>X,<span class="at">type=</span><span class="st">&quot;linear&quot;</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>## [1]  2.79322803  0.03135326  5.00188815  4.00179438 -2.74987113</code></pre>
</div>
</div>
<div id="logistic-regression" class="section level1">
<h1>Logistic regression</h1>
<p>As mentioned, the package can also be used to fit SGS to a Binomial
response. First, we generate some Binomial data. We can use the same
input matrix, <span class="math inline">\(X\)</span>, and true <span class="math inline">\(\beta\)</span> as before.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>sigmoid <span class="ot">=</span> <span class="cf">function</span>(x) {</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>   <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>}</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">ifelse</span>(<span class="fu">sigmoid</span>(data<span class="sc">$</span>X <span class="sc">%*%</span> data<span class="sc">$</span>true_beta <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">400</span>))<span class="sc">&gt;</span><span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>train_y <span class="ot">=</span> y[<span class="dv">1</span><span class="sc">:</span><span class="dv">350</span>] </span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>test_y <span class="ot">=</span> y[<span class="dv">351</span><span class="sc">:</span><span class="dv">400</span>]</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>train_X <span class="ot">=</span> data<span class="sc">$</span>X[<span class="dv">1</span><span class="sc">:</span><span class="dv">350</span>,] </span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>test_X <span class="ot">=</span> data<span class="sc">$</span>X[<span class="dv">351</span><span class="sc">:</span><span class="dv">400</span>,]</span></code></pre></div>
<div id="fitting-and-prediction" class="section level3">
<h3>Fitting and prediction</h3>
<p>We can again apply CV.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>cv_model <span class="ot">=</span> <span class="fu">fit_sgs_cv</span>(<span class="at">X =</span> train_X, <span class="at">y =</span> train_y, <span class="at">groups=</span>groups, <span class="at">type =</span> <span class="st">&quot;logistic&quot;</span>, <span class="at">nlambda =</span> <span class="dv">20</span>, <span class="at">nfolds=</span><span class="dv">10</span>, <span class="at">alpha =</span> <span class="fl">0.95</span>, <span class="at">vFDR =</span> <span class="fl">0.1</span>, <span class="at">gFDR =</span> <span class="fl">0.1</span>, <span class="at">min_frac =</span> <span class="fl">0.05</span>, <span class="at">standardise=</span><span class="st">&quot;l2&quot;</span>,<span class="at">intercept=</span><span class="cn">FALSE</span>,<span class="at">verbose=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Lambda 1/20 done. Lambda: 0.0486. Number of non-zero: 0. Misclassification error: 0.437142857142857. Avg iter: 2&quot;
## [1] &quot;Lambda 2/20 done. Lambda: 0.0415. Number of non-zero: 1. Misclassification error: 0.351428571428571. Avg iter: 4&quot;
## [1] &quot;Lambda 3/20 done. Lambda: 0.0355. Number of non-zero: 2. Misclassification error: 0.331428571428571. Avg iter: 5&quot;
## [1] &quot;Lambda 4/20 done. Lambda: 0.0303. Number of non-zero: 2. Misclassification error: 0.314285714285714. Avg iter: 7&quot;
## [1] &quot;Lambda 5/20 done. Lambda: 0.0259. Number of non-zero: 9. Misclassification error: 0.28. Avg iter: 11&quot;
## [1] &quot;Lambda 6/20 done. Lambda: 0.0221. Number of non-zero: 11. Misclassification error: 0.222857142857143. Avg iter: 9&quot;
## [1] &quot;Lambda 7/20 done. Lambda: 0.0189. Number of non-zero: 13. Misclassification error: 0.208571428571429. Avg iter: 11&quot;
## [1] &quot;Lambda 8/20 done. Lambda: 0.0161. Number of non-zero: 23. Misclassification error: 0.177142857142857. Avg iter: 15&quot;
## [1] &quot;Lambda 9/20 done. Lambda: 0.0138. Number of non-zero: 34. Misclassification error: 0.14. Avg iter: 19&quot;
## [1] &quot;Lambda 10/20 done. Lambda: 0.0118. Number of non-zero: 43. Misclassification error: 0.134285714285714. Avg iter: 20&quot;
## [1] &quot;Lambda 11/20 done. Lambda: 0.0101. Number of non-zero: 57. Misclassification error: 0.131428571428571. Avg iter: 21&quot;
## [1] &quot;Lambda 12/20 done. Lambda: 0.0086. Number of non-zero: 80. Misclassification error: 0.142857142857143. Avg iter: 21&quot;
## [1] &quot;Lambda 13/20 done. Lambda: 0.0073. Number of non-zero: 102. Misclassification error: 0.14. Avg iter: 22&quot;
## [1] &quot;Lambda 14/20 done. Lambda: 0.0063. Number of non-zero: 113. Misclassification error: 0.148571428571429. Avg iter: 26&quot;
## [1] &quot;Lambda 15/20 done. Lambda: 0.0054. Number of non-zero: 120. Misclassification error: 0.145714285714286. Avg iter: 30&quot;
## [1] &quot;Lambda 16/20 done. Lambda: 0.0046. Number of non-zero: 124. Misclassification error: 0.145714285714286. Avg iter: 36&quot;
## [1] &quot;Lambda 17/20 done. Lambda: 0.0039. Number of non-zero: 132. Misclassification error: 0.145714285714286. Avg iter: 45&quot;
## [1] &quot;Lambda 18/20 done. Lambda: 0.0033. Number of non-zero: 136. Misclassification error: 0.137142857142857. Avg iter: 55&quot;
## [1] &quot;Lambda 19/20 done. Lambda: 0.0028. Number of non-zero: 154. Misclassification error: 0.148571428571429. Avg iter: 67&quot;
## [1] &quot;Lambda 20/20 done. Lambda: 0.0024. Number of non-zero: 164. Misclassification error: 0.148571428571429. Avg iter: 81&quot;</code></pre>
<p>and again, use the predict function</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>predictions <span class="ot">=</span> <span class="fu">predict</span>(cv_model<span class="sc">$</span>fit,test_X,<span class="at">type=</span><span class="st">&quot;logistic&quot;</span>)</span></code></pre></div>
<p>In the Binomial case, the function returns both the predicted class
probabilities (<code>response</code>) and the predicted class
(<code>class</code>). We can use this to check the prediction accuracy,
given as <span class="math inline">\(84\%\)</span>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>predictions<span class="sc">$</span>response[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>## [1] 0.4085523 0.6480921 0.1706632 0.1489437 0.3894489</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>predictions<span class="sc">$</span>class[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span></code></pre></div>
<pre><code>## [1] 0 1 0 0 0</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a><span class="fu">sum</span>(predictions<span class="sc">$</span>class <span class="sc">==</span> test_y)<span class="sc">/</span><span class="fu">length</span>(test_y)</span></code></pre></div>
<pre><code>## [1] 0.82</code></pre>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<ul>
<li><a href="https://arxiv.org/abs/2305.09467">Feser, F., Evangelou, M.
(2023). <em>Sparse-group SLOPE: adaptive bi-level selection with
FDR-control</em></a>.</li>
</ul>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
